{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from osgeo import ogr\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import critical_loads as cl\n",
    "import nivapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: ········\n",
      "Password: ········\n",
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# Connect to db\n",
    "ora_eng = nivapy.da.connect(src='nivabase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: ········\n",
      "Password: ········\n",
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# Connect to db\n",
    "pg_eng = nivapy.da.connect(src='postgres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical Loads Workflow - new grid\n",
    "\n",
    "This notebook implements the same workflow as the one [here](http://nbviewer.jupyter.org/github/JamesSample/critical_loads/blob/master/notebooks/critical_loads_workflow.ipynb), but using the new 0.1 degree vector grid instead of the old BLR grid. Note that this requires adopting an entirely raster-based workflow, so the procedure for water and soils critical loads is different to that described in the previous notebook. The vegetation calculations were already raster-based, so the methodology used here is similar.\n",
    "\n",
    "Details of the spatial processing required to enable switching to the new 0.1 degree deposition grid are provided in [this notebook](http://nbviewer.jupyter.org/github/JamesSample/critical_loads/blob/master/notebooks/new_grid.ipynb).\n",
    "\n",
    "**NB:** This notebook is designed for processing one dataset at a time i.e. the looping over time periods implemented in the previous notebook is not repeated here (the previous notebook was used for historic calculations and evaluating the new code base, which is not applicable here).\n",
    "\n",
    "## 1. Vegetation\n",
    "\n",
    "A new raster-based workflow was developed in [this notebook](http://nbviewer.jupyter.org/github/JamesSample/critical_loads/blob/master/notebooks/critical_loads_vegetation.ipynb). The code below creates vegetation exceedance grids (in mg-N/l) for the time periods of interest.\n",
    "\n",
    "### 1.1. Upload new data to database\n",
    "\n",
    "The new deposition data from NILU is supplied as `.dat` files. For an example, see:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\raw_data\\2012_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ID for new series\n",
    "ser_id = 28\n",
    "\n",
    "# Create new series for this data period\n",
    "df = pd.DataFrame({'dep_series_id':ser_id,\n",
    "                   'name':'Middel 2012-2016 (new; hi-res)',\n",
    "                   'description':'Fordelt til BLR av NILU 2017 (Wenche Aas; new method; 0.1 degree grid)'},\n",
    "                  index=[0,])\n",
    "\n",
    "## Add to db\n",
    "#df.to_sql('dep_series_definitions', con=ora_eng, schema='resa2', \n",
    "#          if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>parameter_id</th>\n",
       "      <th>value</th>\n",
       "      <th>dep_series_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50050305</td>\n",
       "      <td>2</td>\n",
       "      <td>270.87</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50050315</td>\n",
       "      <td>2</td>\n",
       "      <td>240.50</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50050325</td>\n",
       "      <td>2</td>\n",
       "      <td>259.19</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50050335</td>\n",
       "      <td>2</td>\n",
       "      <td>252.06</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50050345</td>\n",
       "      <td>2</td>\n",
       "      <td>332.82</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cell_id parameter_id   value  dep_series_id\n",
       "0  50050305            2  270.87             28\n",
       "1  50050315            2  240.50             28\n",
       "2  50050325            2  259.19             28\n",
       "3  50050335            2  252.06             28\n",
       "4  50050345            2  332.82             28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read NILU data\n",
    "data_fold = r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\raw_data\\2012_2016'\n",
    "search_path = os.path.join(data_fold, '*.dat')\n",
    "file_list = glob.glob(search_path)\n",
    "\n",
    "df_list = []\n",
    "for fpath in file_list:\n",
    "    # Get par name\n",
    "    name = os.path.split(fpath)[1].split('_')[:2]\n",
    "    name = '_'.join(name)\n",
    "    \n",
    "    # Read file\n",
    "    df = pd.read_csv(fpath, delim_whitespace=True, header=None,\n",
    "                     names=['lat', 'lon', name])\n",
    "    df.set_index(['lat', 'lon'], inplace=True)    \n",
    "    df_list.append(df)\n",
    "\n",
    "# Combine\n",
    "df = pd.concat(df_list, axis=1)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Calculate unique integer cell ID as latlon \n",
    "# (both *100 and padded to 4 digits)\n",
    "df['cell_id'] = ((df['lat']*100).astype(int).map('{:04d}'.format) + \n",
    "                 (df['lon']*100).astype(int).map('{:04d}'.format))\n",
    "df['cell_id'] = df['cell_id'].astype(int)\n",
    "del df['lat'], df['lon'], df['tot_n']\n",
    "\n",
    "# Rename\n",
    "df.rename(columns={'tot_nhx':2, # N (red)\n",
    "                   'tot_nox':1, # N (oks)\n",
    "                   'tot_s':4},  # Non-marine S\n",
    "          inplace=True)\n",
    "\n",
    "# Melt \n",
    "df = pd.melt(df, var_name='parameter_id', id_vars='cell_id')\n",
    "\n",
    "# Add series ID\n",
    "df['dep_series_id'] = ser_id\n",
    "\n",
    "## Add to db\n",
    "#df.to_sql('dep_grid_0_1deg_values', con=ora_eng, schema='resa2', \n",
    "#          if_exists='append', index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Read lookup table linking vegetation classes to critical loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CL_100smgN/m2/yr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORUTcode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CL_100smgN/m2/yr\n",
       "NORUTcode                  \n",
       "1                         5\n",
       "2                         5\n",
       "3                         5\n",
       "4                        10\n",
       "5                        10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read lookup table\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\vegetation'\n",
    "           r'\\sat_veg_land_use_classes.xlsx')\n",
    "df = pd.read_excel(in_xlsx, sheetname='EUNIS_tilGIS', index_col=0)\n",
    "\n",
    "df = df[['CL_100smgN/m2/yr']].round(0).astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Reclassify\n",
    "\n",
    "Unless the critical loads change, this cell only needs running once. `sat_veg_30m_cr_lds_div100.tif` can then be used in subsequent calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Input national veg map\n",
    "#in_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "#          r'\\GIS\\Raster\\vegetation\\sat_veg_30m_all.tif')\n",
    "#\n",
    "## Output geotiff for critical loads values\n",
    "#out_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "#           r'\\GIS\\Raster\\vegetation\\sat_veg_30m_cr_lds_div100.tif')\n",
    "#\n",
    "## Mask raster for land defined by BLR\n",
    "#mask_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "#            r'\\GIS\\Raster\\blr_land_mask.tif')\n",
    "#\n",
    "## Reclassify\n",
    "#cl.reclassify_raster(in_tif, mask_tif, out_tif, df, 'CL_100smgN/m2/yr', 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Get deposition data from database\n",
    "\n",
    "**Note:** Remember to add the new `dep_series_id` to the query below, as well as a new name in `df.columns`. The resulting dataframe should have just a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.32 3593.19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ndep1216_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50050305</th>\n",
       "      <td>497.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50050315</th>\n",
       "      <td>455.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50050325</th>\n",
       "      <td>473.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50050335</th>\n",
       "      <td>471.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50050345</th>\n",
       "      <td>574.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ndep1216_3\n",
       "cell_id             \n",
       "50050305      497.23\n",
       "50050315      455.25\n",
       "50050325      473.62\n",
       "50050335      471.73\n",
       "50050345      574.69"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all dep values\n",
    "sql = (\"SELECT cell_id, dep_series_id as series, value as dep \"\n",
    "       \"FROM resa2.dep_grid_0_1deg_values \"\n",
    "       \"WHERE parameter_id IN (1, 2) \"\n",
    "       \"AND dep_series_id = 28\")\n",
    "\n",
    "df = pd.read_sql(sql, ora_eng)\n",
    "\n",
    "# Sum N_oks and N_red\n",
    "df = df.groupby(['cell_id', 'series']).sum()\n",
    "\n",
    "# Reshape and tidy\n",
    "df = df.unstack()\n",
    "df.columns = df.columns.get_level_values(1)\n",
    "df.columns.name = ''\n",
    "df.columns = ['Ndep1216_3'] # '3' means 'new method; new grid'. Must be <=10 chars for shp\n",
    "\n",
    "print np.nanmin(df.values), np.nanmax(df.values)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Process vegetation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Ndep1216_3\n",
      "    Building deposition shapefile...\n",
      "    Rasterising shapefile...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:77: RuntimeWarning: invalid value encountered in greater\n",
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:80: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Calculating exceedance...\n",
      "    Saving exceedance grid...\n",
      "    Done.\n",
      "Finished.\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Path to raw BLR shapefile\n",
    "in_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS'\n",
    "          r'\\Shapefiles\\grid_0_1deg\\crit_lds_0_1deg_grid_clip_utm_z33n.shp')\n",
    "\n",
    "# Snap raster\n",
    "snap_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "            r'\\GIS\\Raster\\vegetation\\sat_veg_30m_all.tif')\n",
    "\n",
    "# Critical loads raster\n",
    "cl_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "          r'\\GIS\\Raster\\vegetation\\sat_veg_30m_cr_lds_div100.tif')\n",
    "\n",
    "# Container for output\n",
    "data_dict = {'nor_area_km2':[],\n",
    "             'ex_area_km2':[]}\n",
    "\n",
    "# Loop over series\n",
    "for ser in df.columns:    \n",
    "    \n",
    "    print 'Processing: %s' % ser\n",
    "    print '    Building deposition shapefile...'\n",
    "    \n",
    "    # Get deposition\n",
    "    dep_df = df[[ser]].dropna(how='any').round(0).astype(int).reset_index()\n",
    "\n",
    "    # Rename cols to match shapefile\n",
    "    dep_df.columns = ['cell_id', ser]\n",
    "\n",
    "    # Read shapefile\n",
    "    blr_df = gpd.read_file(in_shp)\n",
    "\n",
    "    # Join and tidy\n",
    "    dep_df = blr_df.merge(dep_df, on='cell_id')\n",
    "    del dep_df['area_m2']\n",
    "    \n",
    "    # Write output shapefile\n",
    "    dep_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS'\n",
    "               r'\\Shapefiles\\deposition\\dep_%s.shp' % ser)\n",
    "    dep_df.to_file(dep_shp)\n",
    "    \n",
    "    # Convert shp to ras\n",
    "    print '    Rasterising shapefile...'\n",
    "    \n",
    "    # Output BLR raster\n",
    "    dep_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "               r'\\GIS\\Raster\\deposition\\dep_%s_30m.tif' % ser)\n",
    "\n",
    "    cl.vec_to_ras(dep_shp, dep_tif, snap_tif, ser, -1, gdal.GDT_Int16)\n",
    "    \n",
    "    # Exceedance\n",
    "    print '    Calculating exceedance...'\n",
    "    \n",
    "    # Read grids\n",
    "    cl_grid, cl_ndv = cl.read_geotiff(cl_tif)\n",
    "    dep_grid, dep_ndv = cl.read_geotiff(dep_tif)\n",
    "\n",
    "    # Upcast to float32 for safe handling of negative values\n",
    "    cl_grid = cl_grid.astype(np.float32)\n",
    "    dep_grid = dep_grid.astype(np.float32)\n",
    "   \n",
    "    # Set ndv\n",
    "    cl_grid[cl_grid==cl_ndv] = np.nan\n",
    "    dep_grid[dep_grid==dep_ndv] = np.nan\n",
    "\n",
    "    # Get total area of non-NaN from dep grid\n",
    "    nor_area = np.count_nonzero(~np.isnan(dep_grid))*30.*30./1.E6\n",
    "\n",
    "    # Apply scaling factor to CLs\n",
    "    cl_grid = cl_grid*100.\n",
    "\n",
    "    # Exceedance\n",
    "    ex_grid = dep_grid - cl_grid\n",
    "    del dep_grid, cl_grid  \n",
    "    \n",
    "    # Get total area exceeded\n",
    "    ex_area = np.count_nonzero(ex_grid > 0)*30.*30./1.E6\n",
    "\n",
    "    # Set <0 to 0\n",
    "    ex_grid[ex_grid<0] = 0\n",
    "    \n",
    "    # Reset ndv\n",
    "    ex_grid[np.isnan(ex_grid)] = -1\n",
    "\n",
    "    # Downcast to int16 to save space\n",
    "    ex_grid = ex_grid.round(0).astype(np.int16)\n",
    "    \n",
    "    # Append results\n",
    "    data_dict['nor_area_km2'].append(nor_area)\n",
    "    data_dict['ex_area_km2'].append(ex_area)\n",
    "    \n",
    "    # Write output\n",
    "    print '    Saving exceedance grid...'\n",
    "    ex_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "              r'\\GIS\\Raster\\exceedance\\exceed_%s_30m.tif' % ser)\n",
    "    \n",
    "    cl.write_geotiff(ex_grid, ex_tif, snap_tif, -1, gdal.GDT_Int16)\n",
    "    del ex_grid\n",
    "    print '    Done.'\n",
    "\n",
    "# Build output df\n",
    "ex_df = pd.DataFrame(data_dict, index=['vegetation',])\n",
    "ex_df['ex_pct'] = 100 * ex_df['ex_area_km2'] / ex_df['nor_area_km2']\n",
    "ex_df = ex_df.round(0).astype(int)\n",
    "\n",
    "print 'Finished.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Print national exceedance summary for vegetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_area_km2</th>\n",
       "      <th>nor_area_km2</th>\n",
       "      <th>ex_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vegetation</th>\n",
       "      <td>64264</td>\n",
       "      <td>322184</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ex_area_km2  nor_area_km2  ex_pct\n",
       "vegetation        64264        322184      20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exceedance summary\n",
    "ex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Water\n",
    "\n",
    "The calculations for soil and water involve parameters estimated on the old BLR grid. We do not want/are not able to recalculate these values, so instead I'll use a raster-based workflow where the deposition (0.1 degree grid) and parameter (BLR grid) values are all converted to a standard 120 m grid, and then processed in a consistent way. \n",
    "\n",
    "### 2.1. Deposition data\n",
    "\n",
    "#### 2.1.1. Extract deposition data\n",
    "\n",
    "**Note:** Remember to add the new `dep_series_id` to the query below.\n",
    "\n",
    "This data is on a 0.1 degree grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>N_2012-2016 (new; hi-res)</th>\n",
       "      <th>S_2012-2016 (new; hi-res)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50050305</td>\n",
       "      <td>35.516429</td>\n",
       "      <td>7.398004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50050315</td>\n",
       "      <td>32.517857</td>\n",
       "      <td>7.159077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50050325</td>\n",
       "      <td>33.830000</td>\n",
       "      <td>7.618840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50050335</td>\n",
       "      <td>33.695000</td>\n",
       "      <td>6.792265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50050345</td>\n",
       "      <td>41.049286</td>\n",
       "      <td>7.900187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cell_id  N_2012-2016 (new; hi-res)  S_2012-2016 (new; hi-res)\n",
       "0  50050305                  35.516429                   7.398004\n",
       "1  50050315                  32.517857                   7.159077\n",
       "2  50050325                  33.830000                   7.618840\n",
       "3  50050335                  33.695000                   6.792265\n",
       "4  50050345                  41.049286                   7.900187"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dep data\n",
    "sql = (\"SELECT a.cell_id, b.name AS series, c.name AS par, a.value AS dep \"\n",
    "       \"FROM resa2.dep_grid_0_1deg_values a, \"\n",
    "       \"resa2.dep_series_definitions b, \"\n",
    "       \"resa2.air_parameter_definitions c \"\n",
    "       \"WHERE a.parameter_id IN (1, 2, 4) \"\n",
    "       \"AND a.dep_series_id = 28 \"\n",
    "       \"AND a.parameter_id = c.parameter_id \"\n",
    "       \"AND a.dep_series_id = b.dep_series_id\")\n",
    "\n",
    "dep_df = pd.read_sql(sql, ora_eng)\n",
    "\n",
    "# Tidy\n",
    "dep_df['series'] = dep_df['series'].str[7:]\n",
    "dep_df['par'] = dep_df['par'].str[:1]\n",
    "\n",
    "# Group N(oks) and N(red)\n",
    "dep_df = dep_df.groupby(['cell_id', 'series', 'par']).sum()\n",
    "\n",
    "# Unstack\n",
    "dep_df = dep_df.unstack('par')\n",
    "dep_df.columns = dep_df.columns.get_level_values('par')\n",
    "\n",
    "# Convert to meq/l\n",
    "dep_df['N'] = dep_df['N'] / 14.\n",
    "dep_df['S'] = dep_df['S']*2. / 32.06\n",
    "\n",
    "# Unstack\n",
    "dep_df = dep_df.unstack('series')\n",
    "\n",
    "# Flatten col index\n",
    "dep_df.columns = ['%s_%s' % (p, d) for p, d in zip(dep_df.columns.get_level_values('par'), \n",
    "                                                   dep_df.columns.get_level_values('series'))]\n",
    "dep_df.reset_index(inplace=True)\n",
    "\n",
    "dep_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Convert to raster\n",
    "\n",
    "The code below gets the 0.1 degree spatial data from the database and creates a shapefile including the deposition data above. This is then converted to two 120 m rasters (one for N and one for S)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geom</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(POLYGON ((71329.03767688642 6901331.461400039...</td>\n",
       "      <td>31.942857</td>\n",
       "      <td>7.791641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(POLYGON ((566881.4284799806 7543730.21153602,...</td>\n",
       "      <td>14.319286</td>\n",
       "      <td>10.567062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(POLYGON ((3599.541798072867 6718792.067247962...</td>\n",
       "      <td>55.578571</td>\n",
       "      <td>13.972551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(POLYGON ((11158.06838512811 6605546.052893229...</td>\n",
       "      <td>63.875000</td>\n",
       "      <td>14.380536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(POLYGON ((1020339.017845268 7801865.54714183,...</td>\n",
       "      <td>6.342143</td>\n",
       "      <td>5.036182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                geom          N          S\n",
       "0  (POLYGON ((71329.03767688642 6901331.461400039...  31.942857   7.791641\n",
       "1  (POLYGON ((566881.4284799806 7543730.21153602,...  14.319286  10.567062\n",
       "2  (POLYGON ((3599.541798072867 6718792.067247962...  55.578571  13.972551\n",
       "3  (POLYGON ((11158.06838512811 6605546.052893229...  63.875000  14.380536\n",
       "4  (POLYGON ((1020339.017845268 7801865.54714183,...   6.342143   5.036182"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read 0.1 deg spatial data\n",
    "sql = (\"SELECT * FROM public.dep_grid_0_1deg\")\n",
    "crs = {'init': 'epsg:4326'} # WGS84\n",
    "gdf = gpd.GeoDataFrame.from_postgis(sql, geom_col='geom', crs=crs, con=pg_eng)\n",
    "\n",
    "# Project \n",
    "gdf = gdf.to_crs({'init': 'epsg:32633'}) # UTM Zone 33N\n",
    "\n",
    "# Join\n",
    "gdf = gdf.merge(dep_df, on='cell_id')\n",
    "\n",
    "# Tidy\n",
    "del gdf['lat'], gdf['lon'], gdf['area_m2'], gdf['cell_id']\n",
    "\n",
    "# Simplify col names due to shp limits\n",
    "gdf.columns = [i.split('_')[0] for i in gdf.columns]\n",
    "\n",
    "# Save to shp\n",
    "dep_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS\\Shapefiles'\n",
    "           r'\\deposition\\dep_ns_meq_2012_16_new_meth_0_1deg.shp')\n",
    "gdf.to_file(driver='ESRI Shapefile', filename=dep_shp)\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 120 m snap raster\n",
    "snap_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS'\n",
    "            r'\\Raster\\vegetation\\sat_veg_120m_all.tif')\n",
    "\n",
    "# Raster folder\n",
    "data_fold = r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS\\Raster'\n",
    "\n",
    "# Loop over pars\n",
    "for col in ['N', 'S']:\n",
    "    # Output raster    \n",
    "    dep_tif = os.path.join(data_fold, 'deposition', 'dep_2012_16_%s_meq_120m.tif' % col)\n",
    "\n",
    "    # Rasterise shapefile\n",
    "    cl.vec_to_ras(dep_shp, dep_tif, snap_tif, col, -1, gdal.GDT_Float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Critical loads\n",
    "\n",
    "#### 2.2.1. Get critical loads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blr</th>\n",
       "      <th>claoaavaroaa</th>\n",
       "      <th>eno3fl</th>\n",
       "      <th>clminn</th>\n",
       "      <th>clmaxnoaa</th>\n",
       "      <th>clmaxsoaa</th>\n",
       "      <th>clmins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60506013</td>\n",
       "      <td>46.689055</td>\n",
       "      <td>20.499</td>\n",
       "      <td>3.204124</td>\n",
       "      <td>59.153507</td>\n",
       "      <td>47.083568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60508003</td>\n",
       "      <td>47.240467</td>\n",
       "      <td>8.988</td>\n",
       "      <td>3.204124</td>\n",
       "      <td>70.544508</td>\n",
       "      <td>48.610725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60509002</td>\n",
       "      <td>48.396218</td>\n",
       "      <td>0.029</td>\n",
       "      <td>14.635616</td>\n",
       "      <td>100.955383</td>\n",
       "      <td>51.368535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60511002</td>\n",
       "      <td>11.156834</td>\n",
       "      <td>0.080</td>\n",
       "      <td>7.077605</td>\n",
       "      <td>27.656760</td>\n",
       "      <td>11.903564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60511006</td>\n",
       "      <td>34.764804</td>\n",
       "      <td>1.081</td>\n",
       "      <td>42.316831</td>\n",
       "      <td>121.992502</td>\n",
       "      <td>38.498971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        blr  claoaavaroaa  eno3fl     clminn   clmaxnoaa  clmaxsoaa  clmins\n",
       "0  60506013     46.689055  20.499   3.204124   59.153507  47.083568       0\n",
       "1  60508003     47.240467   8.988   3.204124   70.544508  48.610725       0\n",
       "2  60509002     48.396218   0.029  14.635616  100.955383  51.368535       0\n",
       "3  60511002     11.156834   0.080   7.077605   27.656760  11.903564       0\n",
       "4  60511006     34.764804   1.081  42.316831  121.992502  38.498971       0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dep data\n",
    "sql = (\"SELECT blr, claoaavaroaa, eno3fl, clminn, clmaxnoaa, clmaxsoaa \"\n",
    "       \"FROM resa2.cla\")\n",
    "cl_df = pd.read_sql(sql, ora_eng)\n",
    "\n",
    "# Set index\n",
    "cl_df.index = cl_df['blr']\n",
    "del cl_df['blr']\n",
    "\n",
    "# Add CLSmin as 0\n",
    "cl_df['clmins'] = 0\n",
    "\n",
    "# Tidy\n",
    "cl_df.reset_index(inplace=True)\n",
    "\n",
    "cl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Convert to raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>claoaavaroaa</th>\n",
       "      <th>eno3fl</th>\n",
       "      <th>clminn</th>\n",
       "      <th>clmaxnoaa</th>\n",
       "      <th>clmaxsoaa</th>\n",
       "      <th>clmins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((-10886.67732153146 6503779.108531611...</td>\n",
       "      <td>28.533538</td>\n",
       "      <td>35.544</td>\n",
       "      <td>3.204124</td>\n",
       "      <td>40.514435</td>\n",
       "      <td>29.056767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((3660.479678658361 6501900.217185441,...</td>\n",
       "      <td>32.029772</td>\n",
       "      <td>27.861</td>\n",
       "      <td>3.204124</td>\n",
       "      <td>43.473268</td>\n",
       "      <td>32.471152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((18211.98529702786 6500076.037824233,...</td>\n",
       "      <td>20.888186</td>\n",
       "      <td>25.137</td>\n",
       "      <td>3.204124</td>\n",
       "      <td>29.564269</td>\n",
       "      <td>21.184960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((32767.70791637653 6498306.548390091,...</td>\n",
       "      <td>18.914393</td>\n",
       "      <td>36.846</td>\n",
       "      <td>25.972633</td>\n",
       "      <td>49.911208</td>\n",
       "      <td>19.189395</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((-11562.15574961301 6498623.842200487...</td>\n",
       "      <td>20.463044</td>\n",
       "      <td>47.587</td>\n",
       "      <td>3.204124</td>\n",
       "      <td>30.057701</td>\n",
       "      <td>20.846989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry  claoaavaroaa  eno3fl  \\\n",
       "0  POLYGON ((-10886.67732153146 6503779.108531611...     28.533538  35.544   \n",
       "1  POLYGON ((3660.479678658361 6501900.217185441,...     32.029772  27.861   \n",
       "2  POLYGON ((18211.98529702786 6500076.037824233,...     20.888186  25.137   \n",
       "3  POLYGON ((32767.70791637653 6498306.548390091,...     18.914393  36.846   \n",
       "4  POLYGON ((-11562.15574961301 6498623.842200487...     20.463044  47.587   \n",
       "\n",
       "      clminn  clmaxnoaa  clmaxsoaa  clmins  \n",
       "0   3.204124  40.514435  29.056767       0  \n",
       "1   3.204124  43.473268  32.471152       0  \n",
       "2   3.204124  29.564269  21.184960       0  \n",
       "3  25.972633  49.911208  19.189395       0  \n",
       "4   3.204124  30.057701  20.846989       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read BLR shp\n",
    "blr_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS\\Shapefiles'\n",
    "           r'\\BLR\\blrgrid_uten_grums_utm_z33n.shp')\n",
    "gdf = gpd.read_file(blr_shp)\n",
    "gdf['blr'] = gdf['BLR']\n",
    "gdf = gdf[['geometry', 'blr']]\n",
    "\n",
    "# Join\n",
    "gdf = gdf.merge(cl_df, on='blr')\n",
    "\n",
    "# Tidy\n",
    "del gdf['blr']\n",
    "\n",
    "# Save to shp\n",
    "cl_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS\\Shapefiles'\n",
    "          r'\\water_cl_pars_blr_grid.shp')\n",
    "gdf.to_file(driver='ESRI Shapefile', filename=cl_shp)\n",
    "\n",
    "# Loop over cols\n",
    "cols = [i[:10] for i in gdf.columns if i != 'geometry'] # 10 char limit in shp files\n",
    "for col in cols:\n",
    "    # Output raster\n",
    "    cl_tif = os.path.join(data_fold, '%s_120m.tif' % col)\n",
    "\n",
    "    # Rasterise shapefile\n",
    "    cl.vec_to_ras(cl_shp, cl_tif, snap_tif, col, -1, gdal.GDT_Float32)    \n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Calculate exceedances\n",
    "\n",
    "#### 2.3.1. SSWC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:24: RuntimeWarning: invalid value encountered in greater\n",
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:27: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_area_km2</th>\n",
       "      <th>ex_pct</th>\n",
       "      <th>nor_area_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vegetation</th>\n",
       "      <td>64264</td>\n",
       "      <td>20</td>\n",
       "      <td>322184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_sswc</th>\n",
       "      <td>23298</td>\n",
       "      <td>7</td>\n",
       "      <td>322184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ex_area_km2  ex_pct  nor_area_km2\n",
       "vegetation        64264      20        322184\n",
       "water_sswc        23298       7        322184"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read grids\n",
    "tif_path = os.path.join(data_fold, 'deposition', 'dep_2012_16_S_meq_120m.tif')\n",
    "s_dep, s_ndv = cl.read_geotiff(tif_path)\n",
    "\n",
    "tif_path = os.path.join(data_fold, 'eno3fl_120m.tif')\n",
    "eno3fl, eno_ndv = cl.read_geotiff(tif_path)\n",
    "\n",
    "tif_path = os.path.join(data_fold, 'claoaavaro_120m.tif')\n",
    "claoaavaroaa, cla_ndv = cl.read_geotiff(tif_path)\n",
    "\n",
    "# Set ndv\n",
    "s_dep[s_dep==s_ndv] = np.nan\n",
    "eno3fl[eno3fl==eno_ndv] = np.nan\n",
    "claoaavaroaa[claoaavaroaa==cla_ndv] = np.nan\n",
    "\n",
    "# Get total area of non-NaN from dep grid\n",
    "nor_area = np.count_nonzero(~np.isnan(s_dep))*120.*120./1.E6\n",
    "\n",
    "# Exceedance\n",
    "sswc_ex = s_dep + eno3fl - claoaavaroaa\n",
    "del s_dep, eno3fl, claoaavaroaa  \n",
    "\n",
    "# Get total area exceeded\n",
    "ex_area = np.count_nonzero(sswc_ex > 0)*120.*120./1.E6\n",
    "\n",
    "# Set <0 to 0\n",
    "sswc_ex[sswc_ex<0] = 0\n",
    "\n",
    "# Write geotif\n",
    "sswc_tif = os.path.join(data_fold, 'exceedance', 'sswc_exceed_12_16_meq.tif')\n",
    "cl.write_geotiff(sswc_ex, sswc_tif, snap_tif, -1, gdal.GDT_Float32)\n",
    "del sswc_ex\n",
    "\n",
    "# Build df\n",
    "ex_pct = 100 * ex_area / nor_area\n",
    "ex_df = ex_df.append(pd.DataFrame({'ex_area_km2':ex_area,\n",
    "                                   'nor_area_km2':nor_area,\n",
    "                                   'ex_pct':ex_pct},\n",
    "                                  index=['water_sswc',]))\n",
    "ex_df = ex_df.round(0).astype(int)\n",
    "\n",
    "ex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3. FAB model\n",
    "\n",
    "The processing for the FAB model is quite complicated, because of the nature of the calculations required to estimate exceedances. My [original workflow](http://nbviewer.jupyter.org/github/JamesSample/critical_loads/blob/master/notebooks/critical_loads_workflow.ipynb) using the BLR grid tabulated values for the parameters of interest in each BLR cell (`cln_min, cln_max, cls_min, cls_max, dep_n and dep_s`) and then looped over the rows in this dataframe using the function `exceed_ns_icpm()` (see section 2.3.3 of [this notebook](http://nbviewer.jupyter.org/github/JamesSample/critical_loads/blob/master/notebooks/critical_loads_workflow.ipynb) for details).\n",
    "\n",
    "Looping over dataframes is slow, but for just a few thousand BLR cells it only takes a few seconds. However, in order to combine data from the old BLR grid with the new deposition grid, all calculations are now being rasterised at 120 m resolution. For a bounding box covering the whole of Norway, this correpsonds to a grid of $10349 \\times 14122 = 146 148 578$ cells in total. Looping over 150 million cells using Pandas is not a feasible approach (it's likely to takes days to weeks).\n",
    "\n",
    "The best solution is to construct a \"vectorised\" algorithm that works directly with the 2D arrays (i.e. no looping required). Vectorising the logic required by the FAB calculations is quite a challenge, but I think I've managed it - see `vectorised_exceed_ns_icpm()` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read CL arrays\n",
    "array_dict = {}\n",
    "for name in ['clminn', 'clmaxnoaa', 'clmins', 'clmaxsoaa']:\n",
    "    # Read tif\n",
    "    tif_path = os.path.join(data_fold, '%s_120m.tif' % name)\n",
    "    data, ndv = cl.read_geotiff(tif_path)\n",
    "    \n",
    "    # Set NDV\n",
    "    data[data==ndv] = np.nan\n",
    "    \n",
    "    # Add to dict\n",
    "    array_dict[name] = data\n",
    "    \n",
    "# Read dep arrays\n",
    "for name in ['dep_2012_16_N_meq_120m', 'dep_2012_16_S_meq_120m']:\n",
    "    # Read tif\n",
    "    tif_path = os.path.join(data_fold, 'deposition', '%s.tif' % name) \n",
    "    data, ndv = cl.read_geotiff(tif_path)\n",
    "    \n",
    "    # Set NDV\n",
    "    data[data==ndv] = np.nan\n",
    "    \n",
    "    # Add to dict\n",
    "    array_dict[name] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "critical_loads.py:302: RuntimeWarning: invalid value encountered in less\n",
      "  mask = ((cln_min < 0) | (cln_max < 0) | (cls_min < 0) | (cls_max < 0))\n",
      "critical_loads.py:326: RuntimeWarning: invalid value encountered in less_equal\n",
      "  ((dep_n - cln_max)*ds <= (dep_s - cls_min)*dn) &\n",
      "critical_loads.py:334: RuntimeWarning: invalid value encountered in less_equal\n",
      "  mask = ((dep_s <= cls_min) & (edited == 0))\n",
      "critical_loads.py:341: RuntimeWarning: invalid value encountered in less_equal\n",
      "  mask = ((dep_n <= cln_min) & (edited == 0))\n",
      "critical_loads.py:348: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  mask = ((-(dep_n - cln_max)*dn >= (dep_s - cls_min)*ds) & (edited == 0))\n",
      "critical_loads.py:355: RuntimeWarning: invalid value encountered in less_equal\n",
      "  mask = ((-(dep_n - cln_min)*dn <= (dep_s - cls_max)*ds) & (edited == 0))\n",
      "critical_loads.py:365: RuntimeWarning: invalid value encountered in divide\n",
      "  xf = (dn*s + ds*v)/dd\n",
      "critical_loads.py:366: RuntimeWarning: invalid value encountered in divide\n",
      "  yf = (ds*s - dn*v)/dd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:16: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract arrays from dict\n",
    "cln_min = array_dict['clminn']\n",
    "cln_max = array_dict['clmaxnoaa']\n",
    "cls_min = array_dict['clmins']\n",
    "cls_max = array_dict['clmaxsoaa']\n",
    "dep_n = array_dict['dep_2012_16_N_meq_120m']\n",
    "dep_s = array_dict['dep_2012_16_S_meq_120m']\n",
    "\n",
    "# Estimate exceedances\n",
    "ex_n, ex_s, reg_id = cl.vectorised_exceed_ns_icpm(cln_min, cln_max, \n",
    "                                                  cls_min, cls_max, \n",
    "                                                  dep_n, dep_s)\n",
    "\n",
    "# Get exceeded area\n",
    "ex = ex_n + ex_s\n",
    "ex_area = np.count_nonzero(ex > 0)*120.*120./1.E6\n",
    "nor_area = np.count_nonzero(~np.isnan(dep_s))*120.*120./1.E6\n",
    "ex_pct = 100*ex_area/nor_area\n",
    "\n",
    "ex_df = ex_df.append(pd.DataFrame({'ex_area_km2':ex_area,\n",
    "                                   'nor_area_km2':nor_area,\n",
    "                                   'ex_pct':ex_pct},\n",
    "                                  index=['water_fab',]))\n",
    "ex_df = ex_df.round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write results to geotif\n",
    "# N\n",
    "tif_path = os.path.join(data_fold, 'exceedance', 'fab_exceed_n_12_16_meq.tif')\n",
    "cl.write_geotiff(ex_n, tif_path, snap_tif, -1, gdal.GDT_Float32)\n",
    "\n",
    "# S\n",
    "tif_path = os.path.join(data_fold, 'exceedance', 'fab_exceed_s_12_16_meq.tif')\n",
    "cl.write_geotiff(ex_s, tif_path, snap_tif, -1, gdal.GDT_Float32)\n",
    "\n",
    "# N+S\n",
    "tif_path = os.path.join(data_fold, 'exceedance', 'fab_exceed_ns_12_16_meq.tif')\n",
    "cl.write_geotiff(ex_n+ex_s, tif_path, snap_tif, -1, gdal.GDT_Float32)\n",
    "\n",
    "# Exceedance 'region'\n",
    "tif_path = os.path.join(data_fold, 'exceedance', 'fab_reg_id.tif')\n",
    "cl.write_geotiff(reg_id, tif_path, snap_tif, -1, gdal.GDT_Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_area_km2</th>\n",
       "      <th>ex_pct</th>\n",
       "      <th>nor_area_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vegetation</th>\n",
       "      <td>64264</td>\n",
       "      <td>20</td>\n",
       "      <td>322184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_sswc</th>\n",
       "      <td>23298</td>\n",
       "      <td>7</td>\n",
       "      <td>322184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_fab</th>\n",
       "      <td>61080</td>\n",
       "      <td>19</td>\n",
       "      <td>322184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ex_area_km2  ex_pct  nor_area_km2\n",
       "vegetation        64264      20        322184\n",
       "water_sswc        23298       7        322184\n",
       "water_fab         61080      19        322184"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aside: Testing against \"looping\" approach\n",
    "\n",
    "The results above look reasonable, but the vectorised code is complicated and I'd like to check it's giving the correct results. The code below implements looping, but this time using a more optimised approach compared to Pandas. As [I have found previously](http://nbviewer.jupyter.org/github/JamesSample/misc/blob/master/radb.ipynb#2.-NCBI-dataset), when looping is unavoidable, dropping down to basic Numpy from Pandas can give speed-ups of roughly 1000x, and further gains can be made by using Numba and the @jit decorator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:51: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def fab_loop_numpy(array_dict):\n",
    "    # Get desried shape\n",
    "    shp = array_dict['clminn'].shape\n",
    "    \n",
    "    # Ravel\n",
    "    for key in array_dict.keys():\n",
    "        array_dict[key] = array_dict[key].ravel()\n",
    "        \n",
    "    # Extract ravelled arrays\n",
    "    cln_min = array_dict['clminn']\n",
    "    cln_max = array_dict['clmaxnoaa']\n",
    "    cls_min = array_dict['clmins']\n",
    "    cls_max = array_dict['clmaxsoaa']\n",
    "    dep_n = array_dict['dep_2012_16_N_meq_120m']\n",
    "    dep_s = array_dict['dep_2012_16_S_meq_120m']   \n",
    "    \n",
    "    # Pre-allocate result arrays\n",
    "    ex_n_ar = np.full(shape=dep_n.shape, fill_value=np.nan)\n",
    "    ex_s_ar = np.full(shape=dep_n.shape, fill_value=np.nan)\n",
    "    reg_id_ar = np.full(shape=dep_n.shape, fill_value=np.nan)\n",
    "    \n",
    "    for idx in xrange(len(dep_n)):\n",
    "        # Test for NaN\n",
    "        if np.isnan(dep_s[idx]) or np.isnan(cln_min[idx]):\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            # Calc exceedance\n",
    "            ex_n, ex_s, reg_id = cl.exceed_ns_icpm(cln_min[idx], cln_max[idx],\n",
    "                                                   cls_min[idx], cls_max[idx],\n",
    "                                                   dep_n[idx], dep_s[idx])\n",
    "            ex_n_ar[idx] = ex_n\n",
    "            ex_s_ar[idx] = ex_s\n",
    "            reg_id_ar[idx] = reg_id  \n",
    "    \n",
    "    # Reshape\n",
    "    ex_n_ar = ex_n_ar.reshape(shp)\n",
    "    ex_s_ar = ex_s_ar.reshape(shp)\n",
    "    reg_id_ar = reg_id_ar.reshape(shp)\n",
    "    \n",
    "    return (ex_n_ar, ex_s_ar, reg_id_ar)\n",
    "\n",
    "# Run looped version\n",
    "ex_n2, ex_s2, reg_id2 = fab_loop_numpy(array_dict)\n",
    "\n",
    "# Get exceeded area\n",
    "ex = ex_n + ex_s\n",
    "ex_area = np.count_nonzero(ex > 0)*120.*120./1.E6\n",
    "nor_area = np.count_nonzero(~np.isnan(ex))*120.*120./1.E6\n",
    "ex_pct = 100*ex_area/nor_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_area_km2</th>\n",
       "      <th>ex_pct</th>\n",
       "      <th>nor_area_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>water_fab</th>\n",
       "      <td>61080</td>\n",
       "      <td>19</td>\n",
       "      <td>320584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ex_area_km2  ex_pct  nor_area_km2\n",
       "water_fab        61080      19        320584"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print results for comparison\n",
    "pd.DataFrame({'ex_area_km2':ex_area,\n",
    "              'nor_area_km2':nor_area,\n",
    "              'ex_pct':ex_pct},\n",
    "             index=['water_fab',]).round(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above produces the same output as the vectorised version, but it's around 10 times slower. Based on this, I'm fairly happy that the vectorised version is producing consistent results.\n",
    "\n",
    "## 3. Soil\n",
    "\n",
    "The soil calculations use the \"old\" method - see e-mail from Kari received 01/11/2017 at 13.47. The equation is simply\n",
    "\n",
    "$$E_{soil} = S_{dep} - CL_{soil}$$\n",
    "\n",
    "### 3.1. Deposition data\n",
    "\n",
    "#### 3.1.1. Get deposition data from database\n",
    "\n",
    "**Note:** Remember to add the new `dep_series_id` to the query below, as well as a new name in `df.columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>Sdep1216_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50050305</td>\n",
       "      <td>118.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50050315</td>\n",
       "      <td>114.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50050325</td>\n",
       "      <td>122.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50050335</td>\n",
       "      <td>108.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50050345</td>\n",
       "      <td>126.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cell_id  Sdep1216_3\n",
       "0  50050305      118.59\n",
       "1  50050315      114.76\n",
       "2  50050325      122.13\n",
       "3  50050335      108.88\n",
       "4  50050345      126.64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all dep values for non-marine S\n",
    "# in mg-S/m2/year\n",
    "sql = (\"SELECT cell_id, dep_series_id as series, value as dep \"\n",
    "       \"FROM resa2.dep_grid_0_1deg_values \"\n",
    "       \"WHERE parameter_id = 4 \"\n",
    "       \"AND dep_series_id = 28\")\n",
    "\n",
    "dep_df = pd.read_sql(sql, ora_eng)\n",
    "\n",
    "# Reshape and tidy\n",
    "dep_df = dep_df.pivot(index='cell_id', columns='series', values='dep')\n",
    "dep_df.columns.name = ''\n",
    "dep_df.columns = ['Sdep1216_3'] # '3' means 'new method; new grid'. Must be <=10 chars for shp\n",
    "dep_df.reset_index(inplace=True)\n",
    "\n",
    "dep_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2. Rasterise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geom</th>\n",
       "      <th>Sdep1216</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(POLYGON ((71329.03767688642 6901331.461400039...</td>\n",
       "      <td>124.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(POLYGON ((566881.4284799806 7543730.21153602,...</td>\n",
       "      <td>169.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(POLYGON ((3599.541798072867 6718792.067247962...</td>\n",
       "      <td>223.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(POLYGON ((11158.06838512811 6605546.052893229...</td>\n",
       "      <td>230.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(POLYGON ((1020339.017845268 7801865.54714183,...</td>\n",
       "      <td>80.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                geom  Sdep1216\n",
       "0  (POLYGON ((71329.03767688642 6901331.461400039...    124.90\n",
       "1  (POLYGON ((566881.4284799806 7543730.21153602,...    169.39\n",
       "2  (POLYGON ((3599.541798072867 6718792.067247962...    223.98\n",
       "3  (POLYGON ((11158.06838512811 6605546.052893229...    230.52\n",
       "4  (POLYGON ((1020339.017845268 7801865.54714183,...     80.73"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read 0.1 deg spatial data\n",
    "sql = (\"SELECT * FROM public.dep_grid_0_1deg\")\n",
    "crs = {'init': 'epsg:4326'} # WGS84\n",
    "gdf = gpd.GeoDataFrame.from_postgis(sql, geom_col='geom', crs=crs, con=pg_eng)\n",
    "\n",
    "# Project \n",
    "gdf = gdf.to_crs({'init': 'epsg:32633'}) # UTM Zone 33N\n",
    "\n",
    "# Join\n",
    "gdf = gdf.merge(dep_df, on='cell_id')\n",
    "\n",
    "# Tidy\n",
    "del gdf['lat'], gdf['lon'], gdf['area_m2'], gdf['cell_id']\n",
    "\n",
    "# Simplify col names due to shp limits\n",
    "gdf.columns = [i.split('_')[0] for i in gdf.columns]\n",
    "\n",
    "# Save to shp\n",
    "dep_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS\\Shapefiles'\n",
    "           r'\\deposition\\dep_s_mg_2012_16_new_meth_0_1deg.shp')\n",
    "gdf.to_file(driver='ESRI Shapefile', filename=dep_shp)\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output raster    \n",
    "dep_tif = os.path.join(data_fold, 'deposition', 'dep_2012_16_s_mg_120m.tif')\n",
    "\n",
    "# Rasterise shapefile\n",
    "cl.vec_to_ras(dep_shp, dep_tif, snap_tif, 'Sdep1216', -1, gdal.GDT_Float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Critical loads\n",
    "\n",
    "**Note:** Parameter 86 (`CL-Soil-N`) is strangely named, but the description implies it is the critical load for S.\n",
    "\n",
    "**Note 2:** There is one cell where the critical load is negative. This is filtered out from the calculations - see e-mail from Espen received 16/11/2017 at 13.04.\n",
    "\n",
    "#### 3.2.1. Get CL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blr</th>\n",
       "      <th>crit_ld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58006004</td>\n",
       "      <td>1818.923277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58006007</td>\n",
       "      <td>3237.448624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58006008</td>\n",
       "      <td>3095.109867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58006012</td>\n",
       "      <td>3443.772948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58006015</td>\n",
       "      <td>3062.583133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        blr      crit_ld\n",
       "0  58006004  1818.923277\n",
       "1  58006007  3237.448624\n",
       "2  58006008  3095.109867\n",
       "3  58006012  3443.772948\n",
       "4  58006015  3062.583133"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all CLs for S\n",
    "# in meq/m2/year\n",
    "sql = (\"SELECT blr, xvalue as crit_ld \"\n",
    "       \"FROM resa2.talegren_values \"\n",
    "       \"WHERE talegren_paramid = 86\")\n",
    "\n",
    "cl_df = pd.read_sql(sql, ora_eng)\n",
    "cl_df.index = cl_df['blr']\n",
    "del cl_df['blr']\n",
    "\n",
    "# Convert to mg-S/m2/yr\n",
    "cl_df['crit_ld'] = cl_df['crit_ld']*32.06 / 2.\n",
    "\n",
    "# Remove negative CL\n",
    "cl_df = cl_df.query('crit_ld >= 0')\n",
    "cl_df.reset_index(inplace=True)\n",
    "\n",
    "cl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. Rasterise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>crit_ld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((32767.70791637653 6498306.548390091,...</td>\n",
       "      <td>1818.923277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((16502.92229014495 6486223.97185181, ...</td>\n",
       "      <td>3237.448624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((31110.65535350452 6484450.549406871,...</td>\n",
       "      <td>3095.109867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(POLYGON ((29455.80772649084 6470594.295637381...</td>\n",
       "      <td>3443.772948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(POLYGON ((9788.008991688606 6465964.999445073...</td>\n",
       "      <td>3062.583133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry      crit_ld\n",
       "0  POLYGON ((32767.70791637653 6498306.548390091,...  1818.923277\n",
       "1  POLYGON ((16502.92229014495 6486223.97185181, ...  3237.448624\n",
       "2  POLYGON ((31110.65535350452 6484450.549406871,...  3095.109867\n",
       "3  (POLYGON ((29455.80772649084 6470594.295637381...  3443.772948\n",
       "4  (POLYGON ((9788.008991688606 6465964.999445073...  3062.583133"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read BLR shp\n",
    "blr_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS\\Shapefiles'\n",
    "           r'\\BLR\\blrgrid_uten_grums_utm_z33n.shp')\n",
    "gdf = gpd.read_file(blr_shp)\n",
    "gdf['blr'] = gdf['BLR']\n",
    "gdf = gdf[['geometry', 'blr']]\n",
    "\n",
    "# Join\n",
    "gdf = gdf.merge(cl_df, on='blr')\n",
    "\n",
    "# Tidy\n",
    "del gdf['blr']\n",
    "\n",
    "# Save to shp\n",
    "cl_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS\\Shapefiles'\n",
    "          r'\\soil_cl_pars_blr_grid.shp')\n",
    "gdf.to_file(driver='ESRI Shapefile', filename=cl_shp)\n",
    "\n",
    "# Output raster\n",
    "cl_tif = os.path.join(data_fold, 'soil_cl_mg_120m.tif')\n",
    "\n",
    "# Rasterise shapefile\n",
    "cl.vec_to_ras(cl_shp, cl_tif, snap_tif, 'crit_ld', -1, gdal.GDT_Float32)    \n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Calculate exceedances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:13: RuntimeWarning: invalid value encountered in less\n",
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:20: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_area_km2</th>\n",
       "      <th>ex_pct</th>\n",
       "      <th>nor_area_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vegetation</th>\n",
       "      <td>64264</td>\n",
       "      <td>20</td>\n",
       "      <td>322184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_sswc</th>\n",
       "      <td>23298</td>\n",
       "      <td>7</td>\n",
       "      <td>322184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_fab</th>\n",
       "      <td>61080</td>\n",
       "      <td>19</td>\n",
       "      <td>322184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soil</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ex_area_km2  ex_pct  nor_area_km2\n",
       "vegetation        64264      20        322184\n",
       "water_sswc        23298       7        322184\n",
       "water_fab         61080      19        322184\n",
       "soil                  0       0        108683"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read tifs\n",
    "tif_path = os.path.join(data_fold, 'deposition', 'dep_2012_16_s_mg_120m.tif')\n",
    "dep_s, ndv = cl.read_geotiff(tif_path)\n",
    "dep_s[dep_s==ndv] = np.nan\n",
    "\n",
    "# Read tifs\n",
    "tif_path = os.path.join(data_fold, 'soil_cl_mg_120m.tif')\n",
    "cl_soil, ndv = cl.read_geotiff(tif_path)\n",
    "cl_soil[cl_soil==ndv] = np.nan\n",
    "\n",
    "# Exceedance\n",
    "ex_soil = dep_s - cl_soil\n",
    "ex_soil[ex_soil<0] = 0\n",
    "\n",
    "# Save geotiff\n",
    "tif_path = os.path.join(data_fold, 'exceedance', 'soil_exceed_12_16_mg.tif')\n",
    "cl.write_geotiff(ex_soil, tif_path, snap_tif, -1, gdal.GDT_Float32)\n",
    "\n",
    "# Get exceeded area\n",
    "ex_area = np.count_nonzero(ex_soil > 0)*120.*120./1.E6\n",
    "nor_area = np.count_nonzero(~np.isnan(ex_soil))*120.*120./1.E6\n",
    "ex_pct = 100*ex_area/nor_area\n",
    "\n",
    "ex_df = ex_df.append(pd.DataFrame({'ex_area_km2':ex_area,\n",
    "                                   'nor_area_km2':nor_area,\n",
    "                                   'ex_pct':ex_pct},\n",
    "                                  index=['soil',]))\n",
    "ex_df = ex_df.round(0).astype(int)\n",
    "\n",
    "ex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `'nor_area_km2'` in the soils calculation actually refers to the total area with \"productive forest\" (see e-mail from Kari received 16/11/2017 at 12.52 for details), which is only 662 of the original BLR cells. If the soil exceedance is greater than zero, **the calculation of percent exceedance in the cell above will need modifying to use the true total area of Norway**. For now, it doesn't matter, as the exceeded area is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write ex_df to file\n",
    "out_csv = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "           r'\\areas_exceeded_new_meth_new_grid.csv')\n",
    "ex_df.to_csv(out_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
