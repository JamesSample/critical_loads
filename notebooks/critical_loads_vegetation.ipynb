{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from osgeo import ogr\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import critical_loads as cl\n",
    "from IPython.display import Image\n",
    "import imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical loads for vegetation\n",
    "\n",
    "## 1. Mosaic 30 m land cover data\n",
    "\n",
    "Raw land cover data with 30 m resolution are here:\n",
    "\n",
    "K:\\Avdeling\\317 Klima- og milj√∏modellering\\KAU\\Focal Centre\\Vegetation\\Veg map\\satveg_30\\0\n",
    "\n",
    "I've copied this locally and used the `Mosiac_To_New_Raster` tool in ArcToolbox to combine the tiles into a single 8-bit integer GeoTiff (`sat_veg_30m_all.tif`), which has an uncompressed size of 2.2 GB.\n",
    "\n",
    "## 2. Reclassify vegetation according to critical loads\n",
    "\n",
    "### 2.1. Read lookup table link vegetation classes to critical loads\n",
    "\n",
    "The land use classes for the vegeation map are given here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\sat_veg_land_use_classes.xlsx\n",
    "\n",
    "The first step is to reclassify the land use grid according to the critical loads. Land classes 0, 23, 24 and 25 are not used, so I'll set the values to 255 (for no data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CL_meq/m2/yr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORUTcode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CL_meq/m2/yr\n",
       "NORUTcode              \n",
       "1                    36\n",
       "2                    36\n",
       "3                    36\n",
       "4                    71\n",
       "5                    71\n",
       "6                    36\n",
       "7                    36\n",
       "8                    36\n",
       "9                    36\n",
       "10                   71\n",
       "11                   71\n",
       "12                   36\n",
       "13                   36\n",
       "14                   36\n",
       "15                   36\n",
       "16                   36\n",
       "17                   71\n",
       "18                   71\n",
       "19                   36\n",
       "20                   36\n",
       "21                   36\n",
       "22                   21\n",
       "23                  255\n",
       "24                  255\n",
       "25                  255\n",
       "0                   255"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read lookup table\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "           r'\\sat_veg_land_use_classes.xlsx')\n",
    "df = pd.read_excel(in_xlsx, sheetname='EUNIS_tilGIS', index_col=0)\n",
    "\n",
    "df = df[['CL_meq/m2/yr']].round(0).astype(int)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Reclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input national veg map\n",
    "in_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "          r'\\GIS\\Raster\\sat_veg_30m_all.tif')\n",
    "\n",
    "# Output geotiff for critical loads values\n",
    "out_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "           r'\\GIS\\Raster\\sat_veg_30m_cr_lds.tif')\n",
    "\n",
    "# Reclassify\n",
    "cl.reclassify_raster(in_tif, out_tif, df, 'CL_meq/m2/yr', 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process deposition data\n",
    "\n",
    "### 3.1. Get deposition data from database\n",
    "\n",
    "The deposition data are found in `RESA2.DEP_BLR_VALUES`. Parameter IDs are defined in `RESA2.AIR_PARAMETER_DEFINITIONS` and the various data series are defined in `RESA2.DEP_SERIES_DEFINITIONS`. For vegetation, we calculate exceedance as\n",
    "\n",
    "$$E_{veg} = Dep_N - CL$$\n",
    "\n",
    "where $Dep_N$ is total nitrogen deposition and $CL$ is the critical load (see e-mail from Espen received  03/10/2017 at 14.25). Parameter ID 6 in `RESA2.AIR_PARAMETER_DEFINITIONS` corresponds to `ENTot` in `mEkv/m2/year`, which I assume is what we use for $Dep_N$ in the equation above. The different time series definitions are less obvious to me, and I'm not sure which ones we need to recalculate this year. I have exported this table to:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\dep_series_names.xlsx\n",
    "\n",
    "**Ask Kari/Espen which series we are interested in**. For now, I'll just pick a series at random for use in testing.\n",
    "\n",
    "**Update 05/10/2017:** See e-mail from Kari received 05/10/2017 at 13.11. We are interested in series IDs 1 to 4 and 25. However, these do not have values for `ENTot`, so I instead need to calculate N deposition as the sum of `N (oks)` and `N (red)`, converted to equivalents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "resa2_basic_path = (r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\Upload_Template'\n",
    "                    r'\\useful_resa2_code.py')\n",
    "resa2_basic = imp.load_source('useful_resa2_code', resa2_basic_path)\n",
    "engine, conn = resa2_basic.connect_to_resa2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.98571428571 160.908571429\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ndep78_82</th>\n",
       "      <th>Ndep92_96</th>\n",
       "      <th>Ndep97_01</th>\n",
       "      <th>Ndep02_06</th>\n",
       "      <th>Ndep07_11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58006001</th>\n",
       "      <td>121.428571</td>\n",
       "      <td>126.512143</td>\n",
       "      <td>112.636429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.391429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58006002</th>\n",
       "      <td>123.489286</td>\n",
       "      <td>89.075000</td>\n",
       "      <td>82.091429</td>\n",
       "      <td>85.187857</td>\n",
       "      <td>98.853571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58006003</th>\n",
       "      <td>86.958571</td>\n",
       "      <td>83.657143</td>\n",
       "      <td>75.672857</td>\n",
       "      <td>82.670714</td>\n",
       "      <td>85.939286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58006004</th>\n",
       "      <td>99.449286</td>\n",
       "      <td>93.594286</td>\n",
       "      <td>101.810714</td>\n",
       "      <td>93.010714</td>\n",
       "      <td>79.455714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58006005</th>\n",
       "      <td>92.377143</td>\n",
       "      <td>93.052143</td>\n",
       "      <td>89.655000</td>\n",
       "      <td>74.112143</td>\n",
       "      <td>84.609286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ndep78_82   Ndep92_96   Ndep97_01  Ndep02_06  Ndep07_11\n",
       "blr                                                               \n",
       "58006001  121.428571  126.512143  112.636429        NaN  97.391429\n",
       "58006002  123.489286   89.075000   82.091429  85.187857  98.853571\n",
       "58006003   86.958571   83.657143   75.672857  82.670714  85.939286\n",
       "58006004   99.449286   93.594286  101.810714  93.010714  79.455714\n",
       "58006005   92.377143   93.052143   89.655000  74.112143  84.609286"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all dep values for ENTot (par_id = 6)\n",
    "sql = (\"SELECT blr, dep_series_id as series, value as dep \"\n",
    "       \"FROM resa2.dep_blr_values \"\n",
    "       \"WHERE parameter_id IN (1, 2) \"\n",
    "       \"AND dep_series_id IN (1, 2, 3, 4, 25)\")\n",
    "\n",
    "df = pd.read_sql(sql, engine)\n",
    "\n",
    "# Sum N_oks and N_red and convert to meq\n",
    "df = df.groupby(['blr', 'series']).sum()/14\n",
    "\n",
    "# Reshape and tidy\n",
    "df = df.unstack()\n",
    "df.columns = df.columns.get_level_values(1)\n",
    "df.columns.name = ''\n",
    "df.columns = ['Ndep78_82', 'Ndep92_96', 'Ndep97_01', 'Ndep02_06', 'Ndep07_11']\n",
    "\n",
    "print np.nanmin(df.values), np.nanmax(df.values)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all the values lie between 0 and 255, we can continue to use 8-bit integer grids for storage.\n",
    "\n",
    "For now, just process one column as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLR</th>\n",
       "      <th>Ndep07_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58006001</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58006002</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58006003</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58006004</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58006005</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        BLR  Ndep07_11\n",
       "0  58006001         97\n",
       "1  58006002         98\n",
       "2  58006003         85\n",
       "3  58006004         79\n",
       "4  58006005         84"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get one column as an example\n",
    "dep_df = df[['Ndep07_11']].dropna(how='any').astype(int).reset_index()\n",
    "\n",
    "# Rename cols to match shapefile\n",
    "dep_df.columns = ['BLR', 'Ndep07_11']\n",
    "\n",
    "dep_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Join to BLR grid\n",
    "\n",
    "The deposition values from the dataabse need to be joined to the BLR grid shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLR</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Ndep07_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58006001</td>\n",
       "      <td>POLYGON ((-10886.67732153146 6503779.108531611...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58006002</td>\n",
       "      <td>POLYGON ((3660.479678658361 6501900.217185441,...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58006003</td>\n",
       "      <td>POLYGON ((18211.98529702786 6500076.037824233,...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58006004</td>\n",
       "      <td>POLYGON ((32767.70791637653 6498306.548390091,...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58006005</td>\n",
       "      <td>POLYGON ((-11562.15574961301 6498623.842200487...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        BLR                                           geometry  Ndep07_11\n",
       "0  58006001  POLYGON ((-10886.67732153146 6503779.108531611...         97\n",
       "1  58006002  POLYGON ((3660.479678658361 6501900.217185441,...         98\n",
       "2  58006003  POLYGON ((18211.98529702786 6500076.037824233,...         85\n",
       "3  58006004  POLYGON ((32767.70791637653 6498306.548390091,...         79\n",
       "4  58006005  POLYGON ((-11562.15574961301 6498623.842200487...         84"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read BLR grid\n",
    "in_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS'\n",
    "          r'\\Shapefiles\\blrgrid_uten_grums_utm_z33n.shp')\n",
    "\n",
    "blr_df = gpd.read_file(in_shp)\n",
    "\n",
    "# Join\n",
    "dep_df = blr_df.merge(dep_df, on='BLR')\n",
    "del dep_df['area_m2']\n",
    "\n",
    "dep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to shapefile\n",
    "out_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS'\n",
    "           r'\\Shapefiles\\dep_07-11.shp')\n",
    "\n",
    "dep_df.to_file(out_shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Convert BLR grid to 30 m raster\n",
    "\n",
    "We can now convert the shapefile to a 30 m raster with exactly the same extent etc. as the reclassified vegetation map. As with the vegetation and critical loads maps, all values are stored as 8-bit (= 1 byte) integers to keep file sizes down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BLR grid\n",
    "in_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "          r'\\GIS\\Shapefiles\\dep_07-11.shp')\n",
    "\n",
    "# Output BLR raster\n",
    "out_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "           r'\\GIS\\Raster\\dep_07-11_30m.tif')\n",
    "\n",
    "# Snap raster\n",
    "snap_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "            r'\\GIS\\Raster\\sat_veg_30m_all.tif')\n",
    "\n",
    "# Rasterize\n",
    "cl.vec_to_ras(in_shp, out_tif, snap_tif, 'Ndep07_11', 255, gdal.GDT_Byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate exceedance\n",
    "\n",
    "Exceedance can now be calculated easily by subtracting these grids. Some care is need to properly handle no data values and to avoid arithmetic over-/under-flow. In the code below, I temporarily upcast both grids to 32-bit floats. This is not very memory efficient, but it's easy and with 32 GB of RAM on my laptop it should be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths to CL and DEP grids\n",
    "cl_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "          r'\\GIS\\Raster\\sat_veg_30m_cr_lds.tif')\n",
    "\n",
    "dep_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "           r'\\GIS\\Raster\\dep_07-11_30m.tif')\n",
    "\n",
    "# Read grids\n",
    "cl_grid, cl_ndv = cl.read_geotiff(cl_tif)\n",
    "dep_grid, dep_ndv = cl.read_geotiff(dep_tif)\n",
    "\n",
    "# Upcast to float32 for safe handling of negative values\n",
    "cl_grid = cl_grid.astype(np.float32)\n",
    "dep_grid = dep_grid.astype(np.float32)\n",
    "\n",
    "# Set ndv\n",
    "cl_grid[cl_grid==cl_ndv] = np.nan\n",
    "dep_grid[dep_grid==dep_ndv] = np.nan\n",
    "\n",
    "# Exceedance\n",
    "ex_grid = dep_grid - cl_grid\n",
    "del dep_grid, cl_grid\n",
    "\n",
    "# Reset ndv\n",
    "ex_grid[np.isnan(ex_grid)] = 255\n",
    "\n",
    "# Set <0 to 0\n",
    "ex_grid[ex_grid<0] = 0\n",
    "\n",
    "# Downcast to uint8 to save space\n",
    "ex_grid = ex_grid.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output exceedance\n",
    "out_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "           r'\\GIS\\Raster\\exceed_07-11_30m.tif')\n",
    "\n",
    "# Snap raster\n",
    "snap_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "            r'\\GIS\\Raster\\sat_veg_30m_all.tif')\n",
    "\n",
    "# Write results\n",
    "cl.write_geotiff(ex_grid, out_tif, snap_tif, 255, gdal.GDT_Byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole workflow takes approximately 5 minutes to run, which I think is much faster than the previous vector-based approach. Once I know which deposition series we are interested in, I can restructure the code to loop over all the datasets.\n",
    "\n",
    "An ArcMap file showing the results from this experiemnt can be found on the network here:\n",
    "\n",
    "K:\\Prosjekter\\JES\\Critical_Loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loop over all data\n",
    "\n",
    "The code below combines loops over all 5 datasets. It also calculates proportion of Norway where critical loads have been exceeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Ndep78_82\n",
      "    Building deposition shapefile...\n",
      "    Rasterising shapefile...\n",
      "    Calculating exceedance...\n",
      "    Saving exceedance grid...\n",
      "    Done.\n",
      "Processing: Ndep92_96\n",
      "    Building deposition shapefile...\n",
      "    Rasterising shapefile...\n",
      "    Calculating exceedance...\n",
      "    Saving exceedance grid...\n",
      "    Done.\n",
      "Processing: Ndep97_01\n",
      "    Building deposition shapefile...\n",
      "    Rasterising shapefile...\n",
      "    Calculating exceedance...\n",
      "    Saving exceedance grid...\n",
      "    Done.\n",
      "Processing: Ndep02_06\n",
      "    Building deposition shapefile...\n",
      "    Rasterising shapefile...\n",
      "    Calculating exceedance...\n",
      "    Saving exceedance grid...\n",
      "    Done.\n",
      "Processing: Ndep07_11\n",
      "    Building deposition shapefile...\n",
      "    Rasterising shapefile...\n",
      "    Calculating exceedance...\n",
      "    Saving exceedance grid...\n",
      "    Done.\n",
      "Finished.\n",
      "Wall time: 7min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data\\WinPython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\ipykernel\\__main__.py:75: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Path to raw BLR shapefile\n",
    "in_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS'\n",
    "          r'\\Shapefiles\\blrgrid_uten_grums_utm_z33n.shp')\n",
    "\n",
    "# Snap raster\n",
    "snap_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "            r'\\GIS\\Raster\\sat_veg_30m_all.tif')\n",
    "\n",
    "# Critical loads raster\n",
    "cl_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "          r'\\GIS\\Raster\\sat_veg_30m_cr_lds.tif')\n",
    "\n",
    "# Container for output\n",
    "data_dict = {'series':[],\n",
    "             'nor_area_km2':[],\n",
    "             'ex_area_km2':[]}\n",
    "\n",
    "# Loop over series\n",
    "for ser in ['Ndep78_82', 'Ndep92_96', 'Ndep97_01', 'Ndep02_06', 'Ndep07_11']:    \n",
    "    \n",
    "    print 'Processing: %s' % ser\n",
    "    print '    Building deposition shapefile...'\n",
    "    \n",
    "    # Get deposition\n",
    "    dep_df = df[[ser]].dropna(how='any').astype(int).reset_index()\n",
    "\n",
    "    # Rename cols to match shapefile\n",
    "    dep_df.columns = ['BLR', ser]\n",
    "\n",
    "    # Read shapefile\n",
    "    blr_df = gpd.read_file(in_shp)\n",
    "\n",
    "    # Join and tidy\n",
    "    dep_df = blr_df.merge(dep_df, on='BLR')\n",
    "    del dep_df['area_m2']\n",
    "    \n",
    "    # Write output shapefile\n",
    "    dep_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS'\n",
    "               r'\\Shapefiles\\dep_%s.shp' % ser)\n",
    "    dep_df.to_file(dep_shp)\n",
    "    \n",
    "    # Convert shp to ras\n",
    "    print '    Rasterising shapefile...'\n",
    "    \n",
    "    # Output BLR raster\n",
    "    dep_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "               r'\\GIS\\Raster\\dep_%s_30m.tif' % ser)\n",
    "\n",
    "    cl.vec_to_ras(dep_shp, dep_tif, snap_tif, ser, 255, gdal.GDT_Byte)\n",
    "    \n",
    "    # Exceedance\n",
    "    print '    Calculating exceedance...'\n",
    "    \n",
    "    # Read grids\n",
    "    cl_grid, cl_ndv = cl.read_geotiff(cl_tif)\n",
    "    dep_grid, dep_ndv = cl.read_geotiff(dep_tif)\n",
    "\n",
    "    # Upcast to float32 for safe handling of negative values\n",
    "    cl_grid = cl_grid.astype(np.float32)\n",
    "    dep_grid = dep_grid.astype(np.float32)\n",
    "   \n",
    "    # Set ndv\n",
    "    cl_grid[cl_grid==cl_ndv] = np.nan\n",
    "    dep_grid[dep_grid==dep_ndv] = np.nan\n",
    "\n",
    "    # Get total area of non-NaN from dep grid\n",
    "    nor_area = np.count_nonzero(~np.isnan(dep_grid))*30.*30./1.E6\n",
    "    \n",
    "    # Exceedance\n",
    "    ex_grid = dep_grid - cl_grid\n",
    "    del dep_grid, cl_grid  \n",
    "    \n",
    "    # Get total area exceeded\n",
    "    ex_area = np.count_nonzero(ex_grid > 0)*30.*30./1.E6\n",
    "\n",
    "    # Reset ndv\n",
    "    ex_grid[np.isnan(ex_grid)] = 255\n",
    "\n",
    "    # Set <0 to 0\n",
    "    ex_grid[ex_grid<0] = 0\n",
    "\n",
    "    # Downcast to uint8 to save space\n",
    "    ex_grid = ex_grid.astype(np.uint8)\n",
    "    \n",
    "    # Append results\n",
    "    data_dict['series'].append(ser)\n",
    "    data_dict['nor_area_km2'].append(nor_area)\n",
    "    data_dict['ex_area_km2'].append(ex_area)\n",
    "    \n",
    "    # Write output\n",
    "    print '    Saving exceedance grid...'\n",
    "    ex_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "              r'\\GIS\\Raster\\exceed_%s_30m.tif' % ser)\n",
    "    \n",
    "    cl.write_geotiff(ex_grid, ex_tif, snap_tif, 255, gdal.GDT_Byte)\n",
    "    \n",
    "    print '    Done.'\n",
    "\n",
    "# Build output df\n",
    "ex_df = pd.DataFrame(data_dict)\n",
    "ex_df['ex_pct'] = 100 * ex_df['ex_area_km2'] / ex_df['nor_area_km2']\n",
    "ex_df.index = ex_df['series']\n",
    "del ex_df['series']\n",
    "ex_df = ex_df.round(0).astype(int)\n",
    "\n",
    "# Save\n",
    "out_csv = r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\nor_prop_exceed.csv'\n",
    "ex_df.to_csv(out_csv)\n",
    "\n",
    "print 'Finished.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_area_km2</th>\n",
       "      <th>nor_area_km2</th>\n",
       "      <th>ex_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ndep78_82</th>\n",
       "      <td>91136</td>\n",
       "      <td>320584</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ndep92_96</th>\n",
       "      <td>67036</td>\n",
       "      <td>320584</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ndep97_01</th>\n",
       "      <td>64572</td>\n",
       "      <td>320584</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ndep02_06</th>\n",
       "      <td>67232</td>\n",
       "      <td>320390</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ndep07_11</th>\n",
       "      <td>64569</td>\n",
       "      <td>320584</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ex_area_km2  nor_area_km2  ex_pct\n",
       "series                                      \n",
       "Ndep78_82        91136        320584      28\n",
       "Ndep92_96        67036        320584      21\n",
       "Ndep97_01        64572        320584      20\n",
       "Ndep02_06        67232        320390      21\n",
       "Ndep07_11        64569        320584      20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
