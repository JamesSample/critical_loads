{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import nivapy3 as nivapy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import critical_loads as cl\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Docker PostGIS\n",
    "eng = nivapy.da.connect(src='postgres',\n",
    "                        db_name='critical_loads',\n",
    "                        port = 25432)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical loads for vegetation (high-resolution method; 2018 onwards)\n",
    "\n",
    "In Spring 2018, the worflow for calculating critical loads for vegetation [was refined](http://nbviewer.jupyter.org/github/JamesSample/critical_loads/blob/master/notebooks/critical_loads_workflow_new_grid.ipynb#1.-Vegetation) to make use of new, higher-resolution input datasets. During November 2018, data handling for the Critical Loads project was also redesigned, with the ultimate aim of centralising and migrating all key datasets onto NIVA's new cloud platform. This notebook estimates exceedences of critical loads for vegetation using both the revised (Spring 2018) workflow and the new (November 2018) data structures. Calculations here assume that deposition data are supplied using NILU's 0.1 degree grid, and the vegetation map is based on 30 m resolution **raster** satellite imagery.\n",
    "\n",
    "**Note:** Data supplied prior to 2017-18 use a different deposition grid (the \"BLR\" grid) and vector vegetation data. **The workflow described here only applies to data supplied from 2017-18 onwards**; earlier data is *not* compatible with the calculations described here.    \n",
    "\n",
    "**To do?:** Create a notebook to repeat the old workflow as well?\n",
    "\n",
    "## 1. Upload new deposition data\n",
    "\n",
    "The first step, if desired, is to upload new deposition data for the time period of interest.\n",
    "\n",
    "### 1.1. Define a new deposition series\n",
    "\n",
    "The code below extracts the existing deposition series already defined in the database. Click `Add row` to create a new row at the bottom of the table (initially a duplicate of the last row), then double-click to edit values and define the new data series. Note that all columns are mandatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new deposition series\n",
    "ser_grid = cl.view_dep_series(eng)\n",
    "ser_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new series to database\n",
    "add_df = cl.add_dep_series(ser_grid, eng)\n",
    "add_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Upload deposition data\n",
    "\n",
    "In 2017, NILU supplied raw data for the 0.1 degree grid in `.dat` format. The code here assumes new data are supplied in the same way.\n",
    "\n",
    "Modify the user options in the cell below to match your new data:\n",
    "\n",
    " * `ser_id` is the ID of the new row that was added to the table above\n",
    " \n",
    " * `dat_fold` is the *relative* path to a folder containing **only** the `.dat` files you wish to upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series_id to upload\n",
    "ser_id = 28\n",
    "\n",
    "# Folder containing .dat files\n",
    "dat_fold = r'../../../../raw_data/2012_2016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process NILU data and add to db\n",
    "df = cl.upload_nilu_0_1deg_dep_data(dat_fold, eng, ser_id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate critical loads for vegetation\n",
    "\n",
    "Critical loads for vegatation are calculated as follows:\n",
    "\n",
    " 1. Extract raster data representing critical loads for vegetation in GeoTiff format and save locally\n",
    " \n",
    " 2. Within the database, link deposition data for the time period of interest to the 0.1 degree vector grid provided by NILU\n",
    " \n",
    " 3. Convert the vector grid to a raster with the same properties (extent, cell size etc.) as the critical loads grid\n",
    " \n",
    " 4. Calculate the exceedance for each pixel, $i$, as $Ex_i = Dep_i - CL_i$\n",
    " \n",
    " 5. Save the exceedance grid as a GeoTiff. Also calculate the total exceeded area for Norway as a whole, and the proportion exceeded in each 0.1 degree vector cell\n",
    " \n",
    " 6. Write the results (i.e. the raw raster and the table & vector summaries) back to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series_id to process\n",
    "ser_id = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x7ff4b9f7f080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dep values\n",
    "sql = (\"CREATE TABLE deposition.test_ndep AS ( \"\n",
    "       \"SELECT ST_Transform(b.geom, 32633) AS geom, \"\n",
    "       \"  a.cell_id, \"\n",
    "       \"  a.n_dep \"\n",
    "       \"FROM (SELECT cell_id, SUM(value) as n_dep \"\n",
    "       \"      FROM deposition.dep_values_0_1deg_grid \"\n",
    "       \"      WHERE param_id IN (1, 2) \"\n",
    "       \"      AND series_id = %s \" \n",
    "       \"      GROUP BY cell_id) AS a, \"\n",
    "       \"deposition.dep_grid_0_1deg AS b \"\n",
    "       \"WHERE a.cell_id = b.cell_id)\" % ser_id)\n",
    "eng.execute(sql)\n",
    "\n",
    "# Use 'cell_id' col as primary key\n",
    "sql = (\"ALTER TABLE deposition.test_ndep \"\n",
    "       \"ADD CONSTRAINT test_ndep_pk \"\n",
    "       \"PRIMARY KEY (cell_id)\")\n",
    "eng.execute(sql)\n",
    "\n",
    "# Enforce geom type\n",
    "sql = (\"ALTER TABLE deposition.test_ndep \"\n",
    "       \"ALTER COLUMN geom TYPE geometry(MULTIPOLYGON, 32633) \"\n",
    "       \"USING ST_Multi(ST_SetSRID(geom, 32633))\")\n",
    "eng.execute(sql)\n",
    "\n",
    "# Create sp. index\n",
    "sql = (\"CREATE INDEX test_ndep_spidx \"\n",
    "       \"ON deposition.test_ndep \"\n",
    "       \"USING GIST (geom)\")\n",
    "eng.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reclassify veg\n",
    "sql = (\"CREATE TABLE vegetation.sat_veg_120m_all_rc AS \"\n",
    "       \"SELECT rid, \"\n",
    "       \"  ST_Reclass(rast, 1, \"\n",
    "       \"    (SELECT string_agg(concat('[',key,'-',key,']:', val), ',') \"\n",
    "       \"     FROM ( \"\n",
    "       \"       SELECT norut_code AS key, cl_100smgn_m2_yr AS val \"\n",
    "       \"       FROM vegetation.land_class_crit_lds) lookup), \"\n",
    "       \"    '8BUI', 255) AS rast \"\n",
    "       \"FROM vegetation.sat_veg_120m_all\")\n",
    "eng.execute(sql)\n",
    "\n",
    "# Indexes etc.\n",
    "sql_list = [\"ALTER TABLE vegetation.sat_veg_120m_all_rc ADD CONSTRAINT sat_veg_120m_all_rc_pk PRIMARY KEY (rid)\",\n",
    "            \"CREATE INDEX sat_veg_120m_all_rc_idx ON vegetation.sat_veg_120m_all_rc USING gist(ST_ConvexHull(rast))\"]\n",
    "for sql in sql_list:\n",
    "    eng.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = postgis_raster_to_array(eng, 'sat_veg_crlds_div100', schema='vegetation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f463419f716f42238ab7b2bed9526b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff4840f32e8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "fig = plt.figure()\n",
    "arr = arr[0]*1.0\n",
    "arr[arr==255] = np.nan\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = (\"CREATE TABLE vegetation.exceedance AS \"\n",
    "       \"SELECT ST_Tile(ST_MapAlgebra(vec.rast, ras.rast, '[rast1] - (100*[rast2])', NULL, 'SECOND'), 100, 100) rast \"\n",
    "       \"FROM ( \"\n",
    "       \"  SELECT ST_Union(ST_AsRaster(geom, (SELECT rast FROM vegetation.sat_veg_120m_all_rc LIMIT 1), '32BF', n_dep, -9999)) rast \"\n",
    "       \"  FROM deposition.test_ndep) vec, \"\n",
    "       \"  (SELECT ST_Union(rast) rast from vegetation.sat_veg_120m_all_rc) ras\")\n",
    "eng.execute(sql)\n",
    "\n",
    "\n",
    "#\"CREATE INDEX fields_rast_convexhull_idx ON fields_rast USING gist( ST_ConvexHull(rast) ); \"\n",
    "#\" \"\n",
    "#\"SELECT AddRasterConstraints('fields_rast', 'rast'); \"\n",
    "#\"SELECT ST_CreateOverview('fields_rast'::regclass, 'rast', 2); \"\n",
    "#\"SELECT ST_CreateOverview('fields_rast'::regclass, 'rast', 4); \"\n",
    "#\"SELECT ST_CreateOverview('fields_rast'::regclass, 'rast', 8); \"\n",
    "#\"SELECT ST_CreateOverview('fields_rast'::regclass, 'rast', 16); \"\n",
    "#\"SELECT ST_CreateOverview('fields_rast'::regclass, 'rast', 32); \"\n",
    "#\"SELECT ST_CreateOverview('fields_rast'::regclass, 'rast', 64); \"\n",
    "#\"SELECT ST_CreateOverview('fields_rast'::regclass, 'rast', 128); \"\n",
    "#\"SELECT ST_CreateOverview('fields_rast'::regclass, 'rast', 256); \""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
