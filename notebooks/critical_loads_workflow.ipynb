{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import ogr\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import critical_loads as cl\n",
    "import imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical Loads Workflow\n",
    "\n",
    "This notebook implements a new workflow for the Critical Loads processing. There are three main components: vegetation, water and soils.\n",
    "\n",
    "## 1. Vegetation\n",
    "\n",
    "A new raster-based workflow was developed in [this notebook](http://nbviewer.jupyter.org/github/JamesSample/critical_loads/blob/master/notebooks/critical_loads_vegetation.ipynb). The code below loops over all the datasets to create vegetation exceedance grids (in mg-N/l) for the time periods of interest.\n",
    "\n",
    "### 1.1. Upload new data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code to upload new data to db. Located here:\n",
    "# K:\\Avdeling\\317 Klima- og miljÃ¸modellering\\KAU\\Focal Centre\\Projects\\2017 TÃ¥legrenseprosjekt\\Data\\dep1216_til_NIVA.xlsx\n",
    "\n",
    "# Note some heading in cells below are currently hard-coded and will need adapting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Read lookup table link vegetation classes to critical loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read lookup table\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "           r'\\sat_veg_land_use_classes.xlsx')\n",
    "df = pd.read_excel(in_xlsx, sheetname='EUNIS_tilGIS', index_col=0)\n",
    "\n",
    "df = df[['CL_100smgN/m2/yr']].round(0).astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Reclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input national veg map\n",
    "in_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "          r'\\GIS\\Raster\\sat_veg_30m_all.tif')\n",
    "\n",
    "# Output geotiff for critical loads values\n",
    "out_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "           r'\\GIS\\Raster\\sat_veg_30m_cr_lds_div100.tif')\n",
    "\n",
    "# Reclassify\n",
    "cl.reclassify_raster(in_tif, out_tif, df, 'CL_100smgN/m2/yr', 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Get deposition data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "resa2_basic_path = (r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\Upload_Template'\n",
    "                    r'\\useful_resa2_code.py')\n",
    "resa2_basic = imp.load_source('useful_resa2_code', resa2_basic_path)\n",
    "engine, conn = resa2_basic.connect_to_resa2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all dep values\n",
    "sql = (\"SELECT blr, dep_series_id as series, value as dep \"\n",
    "       \"FROM resa2.dep_blr_values \"\n",
    "       \"WHERE parameter_id IN (1, 2) \"\n",
    "       \"AND dep_series_id IN (1, 2, 3, 4, 25)\")\n",
    "\n",
    "df = pd.read_sql(sql, engine)\n",
    "\n",
    "# Sum N_oks and N_red\n",
    "df = df.groupby(['blr', 'series']).sum()\n",
    "\n",
    "# Reshape and tidy\n",
    "df = df.unstack()\n",
    "df.columns = df.columns.get_level_values(1)\n",
    "df.columns.name = ''\n",
    "df.columns = ['Ndep78_82', 'Ndep92_96', 'Ndep97_01', 'Ndep02_06', 'Ndep07_11']\n",
    "\n",
    "print np.nanmin(df.values), np.nanmax(df.values)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Loop over datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Path to raw BLR shapefile\n",
    "in_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS'\n",
    "          r'\\Shapefiles\\blrgrid_uten_grums_utm_z33n.shp')\n",
    "\n",
    "# Snap raster\n",
    "snap_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "            r'\\GIS\\Raster\\sat_veg_30m_all.tif')\n",
    "\n",
    "# Critical loads raster\n",
    "cl_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "          r'\\GIS\\Raster\\sat_veg_30m_cr_lds_div100.tif')\n",
    "\n",
    "# Container for output\n",
    "data_dict = {'series':[],\n",
    "             'nor_area_km2':[],\n",
    "             'ex_area_km2':[]}\n",
    "\n",
    "# Loop over series\n",
    "for ser in ['Ndep78_82', 'Ndep92_96', 'Ndep97_01', 'Ndep02_06', 'Ndep07_11']:    \n",
    "    \n",
    "    print 'Processing: %s' % ser\n",
    "    print '    Building deposition shapefile...'\n",
    "    \n",
    "    # Get deposition\n",
    "    dep_df = df[[ser]].dropna(how='any').round(0).astype(int).reset_index()\n",
    "\n",
    "    # Rename cols to match shapefile\n",
    "    dep_df.columns = ['BLR', ser]\n",
    "\n",
    "    # Read shapefile\n",
    "    blr_df = gpd.read_file(in_shp)\n",
    "\n",
    "    # Join and tidy\n",
    "    dep_df = blr_df.merge(dep_df, on='BLR')\n",
    "    del dep_df['area_m2']\n",
    "    \n",
    "    # Write output shapefile\n",
    "    dep_shp = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\GIS'\n",
    "               r'\\Shapefiles\\dep_%s.shp' % ser)\n",
    "    dep_df.to_file(dep_shp)\n",
    "    \n",
    "    # Convert shp to ras\n",
    "    print '    Rasterising shapefile...'\n",
    "    \n",
    "    # Output BLR raster\n",
    "    dep_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "               r'\\GIS\\Raster\\dep_%s_30m.tif' % ser)\n",
    "\n",
    "    cl.vec_to_ras(dep_shp, dep_tif, snap_tif, ser, -1, gdal.GDT_Int16)\n",
    "    \n",
    "    # Exceedance\n",
    "    print '    Calculating exceedance...'\n",
    "    \n",
    "    # Read grids\n",
    "    cl_grid, cl_ndv = cl.read_geotiff(cl_tif)\n",
    "    dep_grid, dep_ndv = cl.read_geotiff(dep_tif)\n",
    "\n",
    "    # Upcast to float32 for safe handling of negative values\n",
    "    cl_grid = cl_grid.astype(np.float32)\n",
    "    dep_grid = dep_grid.astype(np.float32)\n",
    "   \n",
    "    # Set ndv\n",
    "    cl_grid[cl_grid==cl_ndv] = np.nan\n",
    "    dep_grid[dep_grid==dep_ndv] = np.nan\n",
    "\n",
    "    # Get total area of non-NaN from dep grid\n",
    "    nor_area = np.count_nonzero(~np.isnan(dep_grid))*30.*30./1.E6\n",
    "\n",
    "    # Apply scaling factor to CLs\n",
    "    cl_grid = cl_grid*100.\n",
    "\n",
    "    # Exceedance\n",
    "    ex_grid = dep_grid - cl_grid\n",
    "    del dep_grid, cl_grid  \n",
    "    \n",
    "    # Get total area exceeded\n",
    "    ex_area = np.count_nonzero(ex_grid > 0)*30.*30./1.E6\n",
    "\n",
    "    # Set <0 to 0\n",
    "    ex_grid[ex_grid<0] = 0\n",
    "    \n",
    "    # Reset ndv\n",
    "    ex_grid[np.isnan(ex_grid)] = -1\n",
    "\n",
    "    # Downcast to int16 to save space\n",
    "    ex_grid = ex_grid.round(0).astype(np.int16)\n",
    "    \n",
    "    # Append results\n",
    "    data_dict['series'].append(ser)\n",
    "    data_dict['nor_area_km2'].append(nor_area)\n",
    "    data_dict['ex_area_km2'].append(ex_area)\n",
    "    \n",
    "    # Write output\n",
    "    print '    Saving exceedance grid...'\n",
    "    ex_tif = (r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads'\n",
    "              r'\\GIS\\Raster\\exceed_%s_30m.tif' % ser)\n",
    "    \n",
    "    cl.write_geotiff(ex_grid, ex_tif, snap_tif, -1, gdal.GDT_Int16)\n",
    "    \n",
    "    print '    Done.'\n",
    "\n",
    "# Build output df\n",
    "ex_df = pd.DataFrame(data_dict)\n",
    "ex_df['ex_pct'] = 100 * ex_df['ex_area_km2'] / ex_df['nor_area_km2']\n",
    "ex_df.index = ex_df['series']\n",
    "del ex_df['series']\n",
    "ex_df = ex_df.round(0).astype(int)\n",
    "\n",
    "# Save\n",
    "out_csv = r'C:\\Data\\James_Work\\Staff\\Kari_A\\Critical_Loads\\nor_prop_exceed.csv'\n",
    "ex_df.to_csv(out_csv)\n",
    "\n",
    "print 'Finished.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Print national exceedance summary for vegetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exceedance summary\n",
    "ex_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
